[{"paper": "http://cs.nyu.edu/~dsontag/papers/AroraEtAl_icml13.pdf", "videoQuestions": [{"question": "What season was the episode from this promo in?", "answers": [["3", false], ["4", false], ["5", false], ["6", true]]}, {"question": "What is the name of the serial killer for the episode?", "answers": [["Ghost Assassin", false], ["Ghost Killer", true], ["Phantom Renegade", false], ["Phantom Killer", false]]}, {"question": "What time did the episode air (American Central Time)?", "answers": [["9pm", false], ["8pm", false], ["7pm", true], ["6pm", false]]}, {"question": "According to the promo, what has the serial killer never done before?", "answers": [["Be violent", false], ["Be untraceable", false], ["Rip out the victim's nails", true], ["Leave a calling card", false]]}, {"question": "How many people were sitting around the campfire where the body fell?", "answers": [["5", false], ["4", true], ["3", false], ["2", false]]}], "videoDesc": "a promo for Fox's smash hit series Bones.", "video": "-icMszNp38w", "paperQuestions": [{"answer": "sanjeev arora", "question": "Who is the primary author of the paper?"}, {"answer": "maximum likelihood objective", "question": "Up to this point, most approaches to topic model learning been based on a(n)...?"}, {"answer": "true", "question": "Posterior inference over document-topic and topic-word distributions is NP-hard. (true/false)"}, {"answer": "anchor word", "question": "A word that appears in one topic and no others is called a(n)...?"}, {"answer": "298", "question": "What was the mean document length for the articles from The New York Times?"}]}, {"paper": "https://bitcoin.org/bitcoin.pdf", "videoQuestions": [{"question": "How long as the Doctor been running through and space for?", "answers": [["Over 80 years", false], ["Over 800 years", false], ["Over 900 years", true], ["Over 9000 years", false]]}, {"question": "Which best describes the first human seen in the promo?", "answers": [["Policeman", true], ["Scientist", false], ["The Doctor", false], ["Medical doctor", false]]}, {"question": "Which actor plays the second Doctor we see in the video?", "answers": [["Jack Black", false], ["Tom Baker", true], ["Matt Smith", false], ["William Hartnell", false]]}, {"question": "What is floating around Tom Baker in the video?", "answers": [["Jelly beans", false], ["Jelly Babies", true], ["Confetti", false], ["Paper", false]]}, {"question": "How many Ood were in the video altogether?", "answers": [["1", true], ["2", false], ["3", false], ["4", false]]}], "videoDesc": "a promo for Doctor Who.", "video": "7hRy2N2CMhQ", "paperQuestions": [{"answer": "satoshi nakamoto", "question": "Who is the primary author of the paper?"}, {"answer": "chain", "question": "The collection of all Bitcoin transactions is called the Block _______"}, {"answer": "merkle tree", "question": "What is the name of the mechanism used to save disk space?"}, {"answer": "false", "question": "The hash of the next block appears in each block. (true/false)"}, {"answer": "4.2", "question": "How many MB per year does the author propose that the block chain will grow?"}]}, {"paper": "http://bioinfo.cs.rice.edu/sites/bioinfo.cs.rice.edu/files/ParkNakhleh.pdf", "videoQuestions": [{"question": "What is the name of the first character mentioned?", "answers": [["Theon", true], ["Tyrion", false], ["Tywin", false], ["Stannis", false]]}, {"question": "How many dragons are seen in the promo?", "answers": [["1", true], ["2", false], ["3", false], ["0", false]]}, {"question": "When the Red Viper says \"Everybody is interested in something...\", who is he talking to?", "answers": [["Tywin", false], ["The Spider", true], ["Grand Maester Pycelle", false], ["The Iron Bank", false]]}, {"question": "What is Tywin eating when he exclaims \"He killed his King!\"?", "answers": [["Meat", false], ["Lemon cakes", false], ["No food, only wine", false], ["Fruit", true]]}, {"question": "How many men are wielding swords behind Ramsey?", "answers": [["1", true], ["2", false], ["3", false], ["4", false]]}], "videoDesc": "a promo for HBO's Game of Thrones.", "video": "D41h6apb-PY", "paperQuestions": [{"answer": "texas", "question": "What American state did the authors of this paper complete this paper in?"}, {"answer": "murpar", "question": "What is the name of the efficient heuristic presented for inferring a phylogenetic network from a collection of gene trees?"}, {"answer": "horizontal gene transfer", "question": "What does HGT stand for?"}, {"answer": "cluster networks", "question": "Huson and Rupp (2008) roposed a method for summarizing a collection of gene trees using what?"}, {"answer": "phyl-o-gen", "question": "What is the name of the tool that the authors used to generate 30-taxon data sets?"}]}]