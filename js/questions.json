[{"paper": "http://cs.nyu.edu/~dsontag/papers/AroraEtAl_icml13.pdf", "videoQuestions": [{"question": "What season was the episode from this promo in?", "answers": [["3", false], ["4", false], ["5", false], ["6", true]]}, {"question": "What is the name of the serial killer for the episode?", "answers": [["Ghost Assassin", false], ["Ghost Killer", true], ["Phantom Renegade", false], ["Phantom Killer", false]]}, {"question": "What time did the episode air (American Central Time)?", "answers": [["9pm", false], ["8pm", false], ["7pm", true], ["6pm", false]]}, {"question": "According to the promo, what has the serial killer never done before?", "answers": [["Be violent", false], ["Be untraceable", false], ["Rip out the victim's nails", true], ["Leave a calling card", false]]}, {"question": "How many people were sitting around the campfire where the body fell?", "answers": [["5", false], ["4", true], ["3", false], ["2", false]]}], "videoDesc": "A promo for Fox's smash hit series Bones.", "video": "-icMszNp38w", "paperQuestions": [{"answer": "sanjeev arora", "question": "Who is the primary author of the paper?"}, {"answer": "maximum likelihood objective", "question": "Up to this point, most approaches to topic model learning been based on a(n)...?"}, {"answer": "true", "question": "Posterior inference over document-topic and topic-word distributions is NP-hard. (true/false)"}, {"answer": "anchor word", "question": "A word that appears in one topic and no others is called a(n)...?"}, {"answer": "298", "question": "What was the mean document length for the articles from The New York Times?"}]}, {"paper": "https://bitcoin.org/bitcoin.pdf", "videoQuestions": [{"question": "How long as the Doctor been running through and space for?", "answers": [["Over 80 years", false], ["Over 800 years", false], ["Over 900 years", true], ["Over 9000 years", false]]}, {"question": "Which best describes the first human seen in the promo?", "answers": [["Policeman", true], ["Scientist", false], ["The Doctor", false], ["Medical doctor", false]]}, {"question": "Which actor plays the second Doctor we see in the video?", "answers": [["Jack Black", false], ["Tom Baker", true], ["Matt Smith", false], ["William Hartnell", false]]}, {"question": "What is floating around Tom Baker in the video?", "answers": [["Jelly beans", false], ["Jelly Babies", true], ["Confetti", false], ["Paper", false]]}, {"question": "How many Ood were in the video altogether?", "answers": [["1", true], ["2", false], ["3", false], ["4", false]]}], "videoDesc": "A promo for Doctor Who.", "video": "7hRy2N2CMhQ", "paperQuestions": [{"answer": "satoshi nakamoto", "question": "Who is the primary author of the paper?"}, {"answer": "chain", "question": "The collection of all Bitcoin transactions is called the Block _______"}, {"answer": "merkle tree", "question": "What is the name of the mechanism used to save disk space?"}, {"answer": "false", "question": "The hash of the next block appears in each block. (true/false)"}, {"answer": "4.2", "question": "How many MB per year does the author propose that the block chain will grow?"}]}]